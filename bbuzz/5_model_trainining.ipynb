{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9176b8e0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Card fraud model training\"\n",
    "date: 2021-06-04\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9420878",
   "metadata": {},
   "source": [
    "## Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce2f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th></tr><tr><td>16</td><td>application_1623086031838_0024</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://javierhead.h.w:8089/proxy/application_1623086031838_0024/\">Link</a></td><td><a target=\"_blank\" href=\"/hopsworks-api/yarnui/https://javiergpu00.h.w:8044/node/containerlogs/container_1623086031838_0024_01_000001/cc_fraud_detection__meb10000\">Link</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "def experiment_wrapper():\n",
    "\n",
    "    import os\n",
    "    import sys\n",
    "    import uuid\n",
    "    import random\n",
    "        \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    from hops import model as hops_model\n",
    "    from hops import hdfs\n",
    "    import hsfs\n",
    "    # Create a connection\n",
    "    connection = hsfs.connection(engine='training')\n",
    "    # Get the feature store handle for the project's feature store\n",
    "    fs = connection.get_feature_store()\n",
    "    # Get training dataset\n",
    "    td_meta = fs.get_training_dataset(\"card_fraud_model\", 1)\n",
    "\n",
    "    input_dim = 9\n",
    "    encoding_dim = 4\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 5\n",
    "    \n",
    "    train_input = td_meta.tf_data(target_name=None, is_training=True)\n",
    "    train_input_not_processed = train_input.tf_record_dataset()\n",
    "\n",
    "    def custom_impl(example):\n",
    "        feature_names = [td_feature.name for td_feature in td_meta.schema] \n",
    "        x = [tf.cast(example[feature_name], tf.float32) for feature_name in feature_names]\n",
    "        return x,x\n",
    "\n",
    "    train_input_custum_processed = train_input_not_processed.map(lambda value: custom_impl(value))\\\n",
    "        .shuffle(EPOCHS * BATCH_SIZE)\\\n",
    "        .repeat(EPOCHS * BATCH_SIZE)\\\n",
    "        .cache()\\\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\\\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "    autoencoder = tf.keras.Sequential()\n",
    "    autoencoder.add(tf.keras.layers.Dense(16,  activation='selu', input_shape=(input_dim,)))\n",
    "    autoencoder.add(tf.keras.layers.Dense(8,  activation='selu'))\n",
    "    autoencoder.add(tf.keras.layers.Dense(4,    activation='linear', name=\"bottleneck\"))\n",
    "    autoencoder.add(tf.keras.layers.Dense(8,  activation='selu'))\n",
    "    autoencoder.add(tf.keras.layers.Dense(16,  activation='selu'))\n",
    "    autoencoder.add(tf.keras.layers.Dense(input_dim,  activation='selu'))\n",
    "\n",
    "    \n",
    "    # Compile the model.\n",
    "    #autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    autoencoder.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                        optimizer= tf.keras.optimizers.Adam(0.001),\n",
    "                        metrics=tf.keras.metrics.MeanSquaredError()\n",
    "                       )\n",
    "\n",
    "    history = autoencoder.fit(\n",
    "        train_input_custum_processed, \n",
    "        verbose=0,\n",
    "        epochs=EPOCHS, \n",
    "        steps_per_epoch=1,\n",
    "        validation_data=train_input_custum_processed,\n",
    "        validation_steps=1\n",
    "    )  \n",
    "    \n",
    "    metrics = {'loss': history.history['loss'][0]}\n",
    "\n",
    "    # Export model\n",
    "    # WARNING(break-tutorial-inline-code): The following code snippet is\n",
    "    # in-lined in tutorials, please update tutorial documents accordingly\n",
    "    # whenever code changes.\n",
    "\n",
    "    export_path = os.getcwd() + '/model-' + str(uuid.uuid4())\n",
    "    print('Exporting trained model to: {}'.format(export_path))\n",
    "    \n",
    "    tf.saved_model.save(autoencoder, export_path)\n",
    "\n",
    "    print('Done exporting!')\n",
    "        \n",
    "    hops_model.export(export_path, \"cardfraudmodel\", metrics=metrics)    \n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9abb14",
   "metadata": {},
   "source": [
    "## Launch experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd40e30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Experiment \n",
      "\n",
      "('hdfs://rpc.namenode.service.consul:8020/Projects/cc_fraud_detection/Experiments/application_1623086031838_0024_1', {'loss': 2.97389817237854, 'log': 'Experiments/application_1623086031838_0024_1/output.log'})"
     ]
    }
   ],
   "source": [
    "from hops import experiment\n",
    "from hops import hdfs\n",
    "\n",
    "experiment.launch(experiment_wrapper, name='card fraud model', local_logdir=True, metric_key='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb407792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}